{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for the data to be loaded\n",
    "data = \"C:/Users/Hp India/Desktop/20_newsgroups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "#load the data using load_files function\n",
    "content = load_files(data, encoding=\"utf-8\", decode_error=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split of content data and target fields\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(content.data, content.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 14997)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting feature set from the loaded documents\n",
    "\n",
    "def Features(X_train):\n",
    "    #dictionary to obtain feature_set\n",
    "    feature_set ={}\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    for doc in X_train:\n",
    "        #remove all stopwords, numbers, special symbols from each documents\n",
    "        removedNumber = re.sub(r'[0-9]+', ' ', doc)\n",
    "        cleanString = re.sub(r\"[^a-zA-Z0-9]+\", ' ', removedNumber)\n",
    "        clean = re.sub(r'\\b\\w{1,3}\\b', ' ', cleanString)\n",
    "        \n",
    "        #tokenized each document\n",
    "        word_tokens = word_tokenize(clean) \n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        for word in filtered_sentence:\n",
    "            \n",
    "            #check for each world check if is a part of dictionary or not\n",
    "            #initialize each world in dictionary with one if not already present\n",
    "            #increase the frequency of world by one if already present\n",
    "            if word not in feature_set:\n",
    "                feature_set[word] = 1\n",
    "            else:\n",
    "                feature_set[word] += 1\n",
    "    \n",
    "    #order the unorderd dictionary in reverse order\n",
    "    #to get most frequent words\n",
    "    data = []\n",
    "    features = []\n",
    "    for keys, values in feature_set.items():\n",
    "        data.append((values,keys))\n",
    "    data.sort(reverse=True)\n",
    "    print(data[0])\n",
    "    \n",
    "    #select top 500 words as features\n",
    "    for i in range(0,500):\n",
    "        features.append(data[i][1])\n",
    "        \n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataSet function for converting X_test/X_train in m*n array form \n",
    "\n",
    "def DataSet(X, features):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #define a numpy array as data_x\n",
    "    data_x = np.zeros((len(X),len(features)))\n",
    "    i = 0\n",
    "    for doc in X:\n",
    "        #remove all stopwords, numbers, special symbols from each documents\n",
    "        \n",
    "        removedNumber = re.sub(r'[0-9]+', ' ', doc)\n",
    "        cleanString = re.sub(r\"[^a-zA-Z0-9]+\", ' ', removedNumber)\n",
    "        clean = re.sub(r'\\b\\w{1,3}\\b', ' ', cleanString)\n",
    "        word_tokens = word_tokenize(clean) \n",
    "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "        for word in filtered_sentence:\n",
    "            \n",
    "            #go through each word in filtered_sentence and convert data\n",
    "            #in numpy array according to frequency of word in document\n",
    "            for sets, j in zip(features, range(len(features))):\n",
    "                if word == sets:\n",
    "                    data_x[i][j] += 1\n",
    "                    break\n",
    "        i += 1\n",
    "        \n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit function for obtaining the sum of frequencies of all the words\n",
    "#in each class of Y_train\n",
    "def fit(X1, Y_train, feature):\n",
    "    #dictionary for all values of each_class\n",
    "    count = {}\n",
    "    class_value = set(Y_train)\n",
    "    for each_class in class_value:\n",
    "        #for each class create dictionary for keeping the sum\n",
    "        #of each words in a feature set\n",
    "        count[each_class] = {}\n",
    "        count[\"total_count\"] = len(Y_train)\n",
    "        current_class_rows = (Y_train == each_class)\n",
    "        X_train_current = X1[current_class_rows]\n",
    "        Y_train_current = Y_train[current_class_rows]\n",
    "        count[each_class][\"total_count1\"] = len(Y_train_current)\n",
    "        count[each_class][\"total_data\"] = X_train_current[:,:].sum()\n",
    "        \n",
    "        for i in range(1,len(feature)+1):\n",
    "            #obtain sum of all the frequencies for each feature\n",
    "            #in a feature_set\n",
    "            count[each_class][i] = X_train_current[:,i-1].sum()\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability function to return probability value for each class\n",
    "def probability(dictionary, x, current_class):\n",
    "    #inital output value for each class\n",
    "    output = np.log(dictionary[current_class][\"total_count1\"]) - np.log(dictionary[\"total_count\"])\n",
    "    number = len(dictionary[current_class].keys())-2\n",
    "    #for loop over all features  \n",
    "    for j in range(1,number+1):\n",
    "        #xj for getting if the word is part of the feature_set\n",
    "        xj = x[j-1]\n",
    "        #if it is the part of the feature set obtain probability value for it\n",
    "        #by formula (number of that word in each class)/(sum of all the words in that class) \n",
    "        #use log probability\n",
    "        #add output values to obtain final probability value for each class\n",
    "        if xj != 0:\n",
    "            count_current_class_with_value_xj = dictionary[current_class][j] + 1\n",
    "            count_current_class = dictionary[current_class][\"total_data\"] + len(dictionary[current_class].keys()) - 2\n",
    "            current_xj_probablity = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
    "            output = output + current_xj_probablity\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictSinglePoint function that return the best class \n",
    "def predictSinglePoint(dictionary, x):\n",
    "    classes = dictionary.keys()\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_count\"):\n",
    "            continue\n",
    "        #for each class call probability function to obtain probability values\n",
    "        p_current_class = probability(dictionary, x, current_class)\n",
    "        #compare probability value obtain with best_p and assign the new value\n",
    "        #to best_p\n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definr predict function that return the predicited values for X_test\n",
    "def predict(dictionary, X_test):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        #for each X in X_test call predictSinglePoint\n",
    "        x_class = predictSinglePoint(dictionary, x)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22912, 'news')\n"
     ]
    }
   ],
   "source": [
    "#feature_set obtain from X_train \n",
    "feature_Set = Features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting X_train in m*n numpy array\n",
    "X1 = DataSet(X_train, feature_Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting X_test in m*n numpy array\n",
    "X2 = DataSet(X_test, feature_Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call fit function\n",
    "dictionary = fit(X1,Y_train, feature_Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call for predict function\n",
    "Y_pred1 = predict(dictionary,X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##classification report using inbulid sklearn MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       274\n",
      "           1       0.88      0.74      0.80       235\n",
      "           2       0.72      0.90      0.80       241\n",
      "           3       0.69      0.59      0.64       248\n",
      "           4       0.64      0.76      0.70       245\n",
      "           5       0.89      0.68      0.77       261\n",
      "           6       0.79      0.95      0.86       238\n",
      "           7       0.80      0.90      0.85       237\n",
      "           8       0.81      0.95      0.87       259\n",
      "           9       0.95      0.92      0.93       247\n",
      "          10       0.94      0.96      0.95       236\n",
      "          11       0.97      0.93      0.95       245\n",
      "          12       0.79      0.88      0.83       256\n",
      "          13       0.84      0.56      0.67       247\n",
      "          14       0.89      0.86      0.88       259\n",
      "          15       0.96      1.00      0.98       240\n",
      "          16       0.78      0.91      0.84       258\n",
      "          17       0.94      0.84      0.89       265\n",
      "          18       0.71      0.67      0.69       254\n",
      "          19       0.63      0.67      0.65       255\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5000\n",
      "   macro avg       0.82      0.82      0.81      5000\n",
      "weighted avg       0.82      0.82      0.81      5000\n",
      "\n",
      "[[180   0   1   0   0   0   0   7  11   0   1   0   3   5   2   0   1   0\n",
      "    0  63]\n",
      " [  0 175   9   5  14   6   7   1   1   0   0   1   8   6   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0 217   7   2  11   2   0   0   0   0   0   1   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   5   8 146  77   3   4   0   0   0   0   0   4   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1  45 187   0   6   1   0   0   0   0   5   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   9  64   2   1 177   4   0   0   0   0   1   1   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0 225   4   0   0   0   0   3   1   4   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   8 213   4   0   0   0   6   1   1   0   2   0\n",
      "    1   1]\n",
      " [  0   0   0   0   0   1   2   7 246   0   2   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   1   5   0 227  10   0   0   1   0   2   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   8 227   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  1   1   0   0   0   1   1   1   2   0   0 229   6   1   1   0   1   0\n",
      "    0   0]\n",
      " [  0   2   0   4   3   0   3   9   2   0   0   1 225   4   3   0   0   0\n",
      "    0   0]\n",
      " [  8   4   0   1   5   1  12  18  32   1   1   1  14 138   4   0   4   0\n",
      "    2   1]\n",
      " [  0   4   0   0   2   0   5   1   5   3   0   0   7   3 224   0   0   1\n",
      "    3   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 240   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 236   1\n",
      "   15   6]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0  13 223\n",
      "   28   0]\n",
      " [  2   0   0   0   0   0   2   0   0   0   1   2   0   1   8   3  25  12\n",
      "  171  27]\n",
      " [ 33   0   0   0   0   0   2   0   0   0   0   0   1   2   0   4  20   1\n",
      "   22 170]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X1, Y_train)\n",
    "Y_pred = clf.predict(X2)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##classification_report for predicted values using naive bayes code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       274\n",
      "           1       0.93      0.73      0.82       235\n",
      "           2       0.72      0.88      0.79       241\n",
      "           3       0.70      0.60      0.65       248\n",
      "           4       0.65      0.80      0.72       245\n",
      "           5       0.84      0.67      0.74       261\n",
      "           6       0.77      0.92      0.84       238\n",
      "           7       0.86      0.86      0.86       237\n",
      "           8       0.80      0.97      0.88       259\n",
      "           9       0.96      0.96      0.96       247\n",
      "          10       0.97      0.95      0.96       236\n",
      "          11       0.98      0.92      0.95       245\n",
      "          12       0.73      0.93      0.82       256\n",
      "          13       0.78      0.60      0.68       247\n",
      "          14       0.93      0.83      0.88       259\n",
      "          15       1.00      1.00      1.00       240\n",
      "          16       0.72      0.93      0.81       258\n",
      "          17       0.93      0.79      0.85       265\n",
      "          18       0.69      0.59      0.64       254\n",
      "          19       0.67      0.52      0.58       255\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5000\n",
      "   macro avg       0.82      0.81      0.81      5000\n",
      "weighted avg       0.82      0.81      0.81      5000\n",
      "\n",
      "[[208   0   0   1   0   0   0   5  15   0   0   0   2   6   2   0   0   1\n",
      "    0  34]\n",
      " [  0 171  10   6  14   9   8   0   0   0   0   1   7   9   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0 211   7   0  16   2   0   0   0   0   0   4   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   3 149  84   1   5   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  41 195   0   5   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   7  67   3   2 174   2   0   0   0   0   2   4   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   3   0 218   6   0   0   0   0   8   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1  11 205   2   0   0   0  13   3   0   0   0   1\n",
      "    1   0]\n",
      " [  0   0   0   0   0   1   2   3 252   0   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   0   0 238   5   0   0   1   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   1   1   8 225   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   0   0   1   1   0   2   0   0 225   8   5   0   0   2   0\n",
      "    0   0]\n",
      " [  1   0   0   3   0   0   5   2   1   0   0   0 238   4   2   0   0   0\n",
      "    0   0]\n",
      " [  8   1   0   2   1   2   9  12  37   0   1   0  21 148   1   0   1   0\n",
      "    2   1]\n",
      " [  2   2   1   0   1   2   7   3   4   1   0   0  13   7 214   0   0   0\n",
      "    1   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 240   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 241   2\n",
      "   10   5]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   0   0   1   0   0  23 209\n",
      "   29   1]\n",
      " [  6   0   0   0   0   0   2   0   0   0   0   1   0   3   7   0  48  11\n",
      "  151  25]\n",
      " [ 68   0   0   0   0   0   3   0   0   0   0   0   1   1   1   0  21   1\n",
      "   26 133]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred1))\n",
    "print(confusion_matrix(Y_test,Y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
